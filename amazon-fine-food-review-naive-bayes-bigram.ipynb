{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/amazon-fine-food-reviews/hashes.txt\n",
      "/kaggle/input/amazon-fine-food-reviews/database.sqlite\n",
      "/kaggle/input/amazon-fine-food-reviews/Reviews.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using SQLite table to read data\n",
    "con  =sqlite3.connect(\"/kaggle/input/amazon-fine-food-reviews/database.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews\n",
    "WHERE Score != 3\n",
    "\"\"\",con)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(x):\n",
    "    if x < 3:\n",
    "        return \"negative\"\n",
    "    return \"positive\"\n",
    "\n",
    "\n",
    "\n",
    "actScore=filtered_data[\"Score\"]\n",
    "\n",
    "positiveNegative = filtered_data[\"Score\"].map(partition)\n",
    "filtered_data[\"Score\"] = positiveNegative\n",
    "#print(filtered_data[\"Score\"])\n",
    "\n",
    "filtered_data.shape\n",
    "\n",
    "filtered_data.head(10)\n",
    "\n",
    "display = pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews\n",
    "WHERE Score != 3 AND UserId = \"AR5J8UI46CURR\"\n",
    "ORDER BY ProductID\n",
    "\"\"\",con)\n",
    "display\n",
    "\n",
    "sorted_data = filtered_data.sort_values(\"ProductId\",axis=0,ascending=True)\n",
    "\n",
    "final= sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"},keep=\"first\",inplace=False)\n",
    "\n",
    "final.shape\n",
    "\n",
    "filtered_data.shape\n",
    "\n",
    "final = final[final[\"HelpfulnessNumerator\"]<=final[\"HelpfulnessDenominator\"]]\n",
    "final.shape\n",
    "\n",
    "#final[\"Time\"].value_counts()\n",
    "\n",
    "display = pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews\n",
    "WHERE Score != 3 AND Time = \"1350345600\"\n",
    "ORDER BY ProductID\n",
    "\"\"\",con)\n",
    "#display\n",
    "#noissue in Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138706</th>\n",
       "      <td>150524</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ACITT7DI6IDDL</td>\n",
       "      <td>shari zychinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>939340800</td>\n",
       "      <td>EVERY book is educational</td>\n",
       "      <td>this witty little book makes my son laugh at l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138688</th>\n",
       "      <td>150506</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2IW4PEEKO2R0U</td>\n",
       "      <td>Tracy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1194739200</td>\n",
       "      <td>Love the book, miss the hard cover version</td>\n",
       "      <td>I grew up reading these Sendak books, and watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138689</th>\n",
       "      <td>150507</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A1S4A3IQ2MU7V4</td>\n",
       "      <td>sally sue \"sally sue\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1191456000</td>\n",
       "      <td>chicken soup with rice months</td>\n",
       "      <td>This is a fun way for children to learn their ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId            ProfileName  \\\n",
       "138706  150524  0006641040   ACITT7DI6IDDL        shari zychinski   \n",
       "138688  150506  0006641040  A2IW4PEEKO2R0U                  Tracy   \n",
       "138689  150507  0006641040  A1S4A3IQ2MU7V4  sally sue \"sally sue\"   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
       "138706                     0                       0  positive   939340800   \n",
       "138688                     1                       1  positive  1194739200   \n",
       "138689                     1                       1  positive  1191456000   \n",
       "\n",
       "                                           Summary  \\\n",
       "138706                   EVERY book is educational   \n",
       "138688  Love the book, miss the hard cover version   \n",
       "138689               chicken soup with rice months   \n",
       "\n",
       "                                                     Text  \n",
       "138706  this witty little book makes my son laugh at l...  \n",
       "138688  I grew up reading these Sendak books, and watc...  \n",
       "138689  This is a fun way for children to learn their ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=final[0:50000]\n",
    "final.shape\n",
    "final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "\n",
    "#stop = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:31<00:00, 1599.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Combining all the above stundents \n",
    "from tqdm import tqdm\n",
    "preprocessed_reviews = []\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(final['Text'].values):\n",
    "    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
    "    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
    "    sentance = decontracted(sentance)\n",
    "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
    "    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sentance = ' '.join(e.lower() for e in sentance.split())\n",
    "    preprocessed_reviews.append(sentance.strip())\n",
    "    #print(preprocessed_reviews)\n",
    "    for e in sentance.split():\n",
    "        sentance=' '.join(e.lower())\n",
    "       #     print(e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#print(preprocessed_reviews[40001])\n",
    "print(len(preprocessed_reviews))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138706</th>\n",
       "      <td>150524</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ACITT7DI6IDDL</td>\n",
       "      <td>shari zychinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>939340800</td>\n",
       "      <td>EVERY book is educational</td>\n",
       "      <td>this witty little book makes my son laugh at l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138688</th>\n",
       "      <td>150506</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2IW4PEEKO2R0U</td>\n",
       "      <td>Tracy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1194739200</td>\n",
       "      <td>Love the book, miss the hard cover version</td>\n",
       "      <td>i grew up reading these sendak books and watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138689</th>\n",
       "      <td>150507</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A1S4A3IQ2MU7V4</td>\n",
       "      <td>sally sue \"sally sue\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1191456000</td>\n",
       "      <td>chicken soup with rice months</td>\n",
       "      <td>this is a fun way for children to learn their ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138690</th>\n",
       "      <td>150508</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AZGXZ2UUK6X</td>\n",
       "      <td>Catherine Hallberg \"(Kate)\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1076025600</td>\n",
       "      <td>a good swingy rhythm for reading aloud</td>\n",
       "      <td>this is a great little book to read aloud it h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138691</th>\n",
       "      <td>150509</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A3CMRKGE0P909G</td>\n",
       "      <td>Teresa</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1018396800</td>\n",
       "      <td>A great way to learn the months</td>\n",
       "      <td>this is a book of poetry about the months of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138693</th>\n",
       "      <td>150511</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A1C9K534BCI9GO</td>\n",
       "      <td>Laura Purdie Salas</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1344211200</td>\n",
       "      <td>Charming and childlike</td>\n",
       "      <td>a charming rhyming book that describes the cir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138694</th>\n",
       "      <td>150512</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A1DJXZA5V5FFVA</td>\n",
       "      <td>A. Conway</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1338249600</td>\n",
       "      <td>Must have.</td>\n",
       "      <td>i set aside at least an hour each day to read ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138695</th>\n",
       "      <td>150513</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ASH0DZQQF6AIZ</td>\n",
       "      <td>tessarat</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1325721600</td>\n",
       "      <td>A classic</td>\n",
       "      <td>i remembered this book from my childhood and g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138696</th>\n",
       "      <td>150514</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2ONB6ZA292PA</td>\n",
       "      <td>Rosalind Matzner</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1313884800</td>\n",
       "      <td>Chicken soup with Rice</td>\n",
       "      <td>it is a great book with adorable illustrations...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138697</th>\n",
       "      <td>150515</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2RTT81R6Y3R7X</td>\n",
       "      <td>Lindylu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1303171200</td>\n",
       "      <td>One of our family's favorite books</td>\n",
       "      <td>this book is a family favorite and was read to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138687</th>\n",
       "      <td>150505</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2PTSM496CF40Z</td>\n",
       "      <td>Jason A. Teeple \"Nobody made a greater mistak...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1210809600</td>\n",
       "      <td>A classic</td>\n",
       "      <td>get the movie or sound track and sing along wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138698</th>\n",
       "      <td>150516</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A3OI7ZGH6WZJ5G</td>\n",
       "      <td>Mary Jane Rogers \"Maedchen\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1293840000</td>\n",
       "      <td>Darling!</td>\n",
       "      <td>the same author wrote where the wild things ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138700</th>\n",
       "      <td>150518</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AK1L4EJBA23JF</td>\n",
       "      <td>L. M. Kraus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1288224000</td>\n",
       "      <td>love this book</td>\n",
       "      <td>great book perfect condition arrived in a shor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138701</th>\n",
       "      <td>150519</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A12HY5OZ2QNK4N</td>\n",
       "      <td>Elizabeth H. Roessner</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1256774400</td>\n",
       "      <td>It's a great book!</td>\n",
       "      <td>i have always loved chicken soup and rice my l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138702</th>\n",
       "      <td>150520</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ADBFSA9KTQANE</td>\n",
       "      <td>James L. Hammock \"Pucks Buddy\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1256688000</td>\n",
       "      <td>Great Gift</td>\n",
       "      <td>this book was purchased as a birthday gift for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138703</th>\n",
       "      <td>150521</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A3RMCRB2NDTDYP</td>\n",
       "      <td>Carol Carruthers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1243468800</td>\n",
       "      <td>This book is great!</td>\n",
       "      <td>my year old daughter brought this book home fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138704</th>\n",
       "      <td>150522</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A1S3C5OFU508P3</td>\n",
       "      <td>Charles Ashbacher</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1219536000</td>\n",
       "      <td>Children will find it entertaining and a gener...</td>\n",
       "      <td>this book contains a collection of twelve shor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138705</th>\n",
       "      <td>150523</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2P4F2UO0UMP8C</td>\n",
       "      <td>Elizabeth A. Curry \"Lovely Librarian\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1096675200</td>\n",
       "      <td>MMMM chicken soup....</td>\n",
       "      <td>summary a young boy describes the usefulness o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138707</th>\n",
       "      <td>150525</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2QID6VCFTY51R</td>\n",
       "      <td>Rick</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1025481600</td>\n",
       "      <td>In December it will be, my snowman's anniversa...</td>\n",
       "      <td>my daughter loves all the really rosie books s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138708</th>\n",
       "      <td>150526</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A3E9QZFE9KXH8J</td>\n",
       "      <td>R. Mitchell</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1129507200</td>\n",
       "      <td>awesome book poor size</td>\n",
       "      <td>this is one of the best children is books ever...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId  \\\n",
       "138706  150524  0006641040   ACITT7DI6IDDL   \n",
       "138688  150506  0006641040  A2IW4PEEKO2R0U   \n",
       "138689  150507  0006641040  A1S4A3IQ2MU7V4   \n",
       "138690  150508  0006641040     AZGXZ2UUK6X   \n",
       "138691  150509  0006641040  A3CMRKGE0P909G   \n",
       "138693  150511  0006641040  A1C9K534BCI9GO   \n",
       "138694  150512  0006641040  A1DJXZA5V5FFVA   \n",
       "138695  150513  0006641040   ASH0DZQQF6AIZ   \n",
       "138696  150514  0006641040   A2ONB6ZA292PA   \n",
       "138697  150515  0006641040  A2RTT81R6Y3R7X   \n",
       "138687  150505  0006641040  A2PTSM496CF40Z   \n",
       "138698  150516  0006641040  A3OI7ZGH6WZJ5G   \n",
       "138700  150518  0006641040   AK1L4EJBA23JF   \n",
       "138701  150519  0006641040  A12HY5OZ2QNK4N   \n",
       "138702  150520  0006641040   ADBFSA9KTQANE   \n",
       "138703  150521  0006641040  A3RMCRB2NDTDYP   \n",
       "138704  150522  0006641040  A1S3C5OFU508P3   \n",
       "138705  150523  0006641040  A2P4F2UO0UMP8C   \n",
       "138707  150525  0006641040  A2QID6VCFTY51R   \n",
       "138708  150526  0006641040  A3E9QZFE9KXH8J   \n",
       "\n",
       "                                             ProfileName  \\\n",
       "138706                                   shari zychinski   \n",
       "138688                                             Tracy   \n",
       "138689                             sally sue \"sally sue\"   \n",
       "138690                       Catherine Hallberg \"(Kate)\"   \n",
       "138691                                            Teresa   \n",
       "138693                                Laura Purdie Salas   \n",
       "138694                                         A. Conway   \n",
       "138695                                          tessarat   \n",
       "138696                                  Rosalind Matzner   \n",
       "138697                                           Lindylu   \n",
       "138687  Jason A. Teeple \"Nobody made a greater mistak...   \n",
       "138698                       Mary Jane Rogers \"Maedchen\"   \n",
       "138700                                       L. M. Kraus   \n",
       "138701                             Elizabeth H. Roessner   \n",
       "138702                    James L. Hammock \"Pucks Buddy\"   \n",
       "138703                                  Carol Carruthers   \n",
       "138704                                 Charles Ashbacher   \n",
       "138705             Elizabeth A. Curry \"Lovely Librarian\"   \n",
       "138707                                              Rick   \n",
       "138708                                       R. Mitchell   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "138706                     0                       0      1   939340800   \n",
       "138688                     1                       1      1  1194739200   \n",
       "138689                     1                       1      1  1191456000   \n",
       "138690                     1                       1      1  1076025600   \n",
       "138691                     3                       4      1  1018396800   \n",
       "138693                     0                       0      1  1344211200   \n",
       "138694                     0                       0      1  1338249600   \n",
       "138695                     0                       0      1  1325721600   \n",
       "138696                     0                       0      1  1313884800   \n",
       "138697                     0                       0      1  1303171200   \n",
       "138687                     1                       1      1  1210809600   \n",
       "138698                     0                       0      1  1293840000   \n",
       "138700                     0                       0      1  1288224000   \n",
       "138701                     0                       0      1  1256774400   \n",
       "138702                     0                       0      1  1256688000   \n",
       "138703                     0                       0      1  1243468800   \n",
       "138704                     0                       0      1  1219536000   \n",
       "138705                     0                       0      1  1096675200   \n",
       "138707                     1                       2      1  1025481600   \n",
       "138708                    11                      18      0  1129507200   \n",
       "\n",
       "                                                  Summary  \\\n",
       "138706                          EVERY book is educational   \n",
       "138688         Love the book, miss the hard cover version   \n",
       "138689                      chicken soup with rice months   \n",
       "138690             a good swingy rhythm for reading aloud   \n",
       "138691                    A great way to learn the months   \n",
       "138693                             Charming and childlike   \n",
       "138694                                         Must have.   \n",
       "138695                                          A classic   \n",
       "138696                             Chicken soup with Rice   \n",
       "138697                 One of our family's favorite books   \n",
       "138687                                          A classic   \n",
       "138698                                           Darling!   \n",
       "138700                                     love this book   \n",
       "138701                                 It's a great book!   \n",
       "138702                                         Great Gift   \n",
       "138703                                This book is great!   \n",
       "138704  Children will find it entertaining and a gener...   \n",
       "138705                              MMMM chicken soup....   \n",
       "138707  In December it will be, my snowman's anniversa...   \n",
       "138708                             awesome book poor size   \n",
       "\n",
       "                                                     Text  \n",
       "138706  this witty little book makes my son laugh at l...  \n",
       "138688  i grew up reading these sendak books and watch...  \n",
       "138689  this is a fun way for children to learn their ...  \n",
       "138690  this is a great little book to read aloud it h...  \n",
       "138691  this is a book of poetry about the months of t...  \n",
       "138693  a charming rhyming book that describes the cir...  \n",
       "138694  i set aside at least an hour each day to read ...  \n",
       "138695  i remembered this book from my childhood and g...  \n",
       "138696  it is a great book with adorable illustrations...  \n",
       "138697  this book is a family favorite and was read to...  \n",
       "138687  get the movie or sound track and sing along wi...  \n",
       "138698  the same author wrote where the wild things ar...  \n",
       "138700  great book perfect condition arrived in a shor...  \n",
       "138701  i have always loved chicken soup and rice my l...  \n",
       "138702  this book was purchased as a birthday gift for...  \n",
       "138703  my year old daughter brought this book home fr...  \n",
       "138704  this book contains a collection of twelve shor...  \n",
       "138705  summary a young boy describes the usefulness o...  \n",
       "138707  my daughter loves all the really rosie books s...  \n",
       "138708  this is one of the best children is books ever...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "final[\"Text\"]=preprocessed_reviews\n",
    "final[\"Score\"]=final[\"Score\"].replace(\"positive\",1)\n",
    "final[\"Score\"]=final[\"Score\"].replace(\"negative\",0)\n",
    "final.head(20)\n",
    "#print(final.iloc[ t : t+1 ,  6 : 7 ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(final['Text'], final[\"Score\"], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(strip_accents='ascii', token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b', lowercase=True,ngram_range=(2,2),min_df=10, max_features=5000)\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "#y_train_cv = cv.fit_transform(y_train)\n",
    "#y_test_cv = cv.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cont_vector=CountVectorizer(ngram_range=(2,2),min_df=10, max_features=5000)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_train_cv, y_train)\n",
    "predictions = naive_bayes.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.88472\n",
      "Precision score:  0.9493609132598302\n",
      "Recall score:  0.9134434847915884\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "print('Accuracy score: ', accuracy_score(y_test, predictions))\n",
    "print('Precision score: ', precision_score(y_test, predictions))\n",
    "print('Recall score: ', recall_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fi_bigram = cont_vector.fit(preprocessed_reviews) #doing only fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"some feature names \", fi_bigram.get_feature_names()[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fi_bigram.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fi_bigram_transformed[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntf_idf_vect = TfidfVectorizer(ngram_range=(1,2), min_df=10)\\ntf_idf_vect.fit(preprocessed_reviews)\\nprint(\"some sample features(unique words in the corpus)\",tf_idf_vect.get_feature_names()[100:110])\\nprint(\\'=\\'*50)\\n\\nfinal_tf_idf = tf_idf_vect.transform(preprocessed_reviews)\\nprint(\"the type of count vectorizer \",type(final_tf_idf))\\nprint(\"the shape of out text TFIDF vectorizer \",final_tf_idf.get_shape())\\nprint(\"the number of unique words including both unigrams and bigrams \", final_tf_idf.get_shape()[1]) '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf\n",
    "'''\n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2), min_df=10)\n",
    "tf_idf_vect.fit(preprocessed_reviews)\n",
    "print(\"some sample features(unique words in the corpus)\",tf_idf_vect.get_feature_names()[100:110])\n",
    "print('='*50)\n",
    "\n",
    "final_tf_idf = tf_idf_vect.transform(preprocessed_reviews)\n",
    "print(\"the type of count vectorizer \",type(final_tf_idf))\n",
    "print(\"the shape of out text TFIDF vectorizer \",final_tf_idf.get_shape())\n",
    "print(\"the number of unique words including both unigrams and bigrams \", final_tf_idf.get_shape()[1]) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i=0\\nlist_of_sentance=[]\\nfor sentance in preprocessed_reviews:\\n    list_of_sentance.append(sentance.split()) '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train your own Word2Vec model using your own text corpus\n",
    "'''i=0\n",
    "list_of_sentance=[]\n",
    "for sentance in preprocessed_reviews:\n",
    "    list_of_sentance.append(sentance.split()) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"w2v_model=Word2Vec(list_of_sentance ,min_count=5,size=50, workers=4)\\nprint(w2v_model.wv.most_similar('great'))\\nprint('='*50) \\nprint(w2v_model.wv.most_similar('worst')) \""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min_count = 5 considers only words that occured atleast 5 times\n",
    "'''w2v_model=Word2Vec(list_of_sentance ,min_count=5,size=50, workers=4)\n",
    "print(w2v_model.wv.most_similar('great'))\n",
    "print('='*50) \n",
    "print(w2v_model.wv.most_similar('worst')) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w2v_words = list(w2v_model.wv.vocab)\\nprint(\"number of words that occured minimum 5 times \",len(w2v_words))\\nprint(\"sample words \", w2v_words[0:50])'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''w2v_words = list(w2v_model.wv.vocab)\n",
    "print(\"number of words that occured minimum 5 times \",len(w2v_words))\n",
    "print(\"sample words \", w2v_words[0:50])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# average Word2Vec\\n# compute average word2vec for each review.\\nsent_vectors = []; # the avg-w2v for each sentence/review is stored in this list\\nfor sent in tqdm(list_of_sentance): # for each review/sentence\\n    sent_vec = np.zeros(50) # as word vectors are of zero length 50, you might need to change this to 300 if you use google's w2v\\n    cnt_words =0; # num of words with a valid vector in the sentence/review\\n    for word in sent: # for each word in a review/sentence\\n        if word in w2v_words:\\n            vec = w2v_model.wv[word]\\n            sent_vec += vec\\n            cnt_words += 1\\n    if cnt_words != 0:\\n        sent_vec /= cnt_words\\n    sent_vectors.append(sent_vec)\\nprint(len(sent_vectors))\\nprint(len(sent_vectors[0])) \""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# average Word2Vec\n",
    "# compute average word2vec for each review.\n",
    "sent_vectors = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sent in tqdm(list_of_sentance): # for each review/sentence\n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length 50, you might need to change this to 300 if you use google's w2v\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        if word in w2v_words:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        sent_vec /= cnt_words\n",
    "    sent_vectors.append(sent_vec)\n",
    "print(len(sent_vectors))\n",
    "print(len(sent_vectors[0])) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model = TfidfVectorizer()\\nmodel.fit(preprocessed_reviews)\\n# we are converting a dictionary with word as a key, and the idf as a value\\ndictionary = dict(zip(model.get_feature_names(), list(model.idf_))) '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# S = [\"abc def pqr\", \"def def def abc\", \"pqr pqr def\"]\n",
    "'''model = TfidfVectorizer()\n",
    "model.fit(preprocessed_reviews)\n",
    "# we are converting a dictionary with word as a key, and the idf as a value\n",
    "dictionary = dict(zip(model.get_feature_names(), list(model.idf_))) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
